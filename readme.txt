1. マイページID
DW000458

2. 学校名
広島大学大学院工学研究科情報工学専攻

3. 氏名
藤田 慎二郎

4. 電話番号
080-5612-5891

5. Eメールアドレス
rightstuff.sora@gmail.com

6. プロダクト概要説明
このプロダクトはTwitterのトレンド解析器を実装したものです．
動作させる際はcronを使うことで常時稼動させることを前提としています．
本プロダクトの基本動作は次のようになります．
まずtiatter_core_hourly.pyを実行することで，
TwitterのStreaming APIから日本語のツイートを取得し，取得したツイートから
単語を抽出する，という動作を繰り返し続けます．
この処理を１時間続けた後，cronによってcalcResults_hourly.pyを実行します．
すると，ここ１時間のトレンド語を計算します．計算した結果はjsonファイルとして
書き出されます．このとき出力先ファイルにはトレンド語だけでなく，その単語がどれだけ
の度合いでトレンドとなっているかの数値と，その単語と頻繁に共起している単語の
上位３つが同時に書き出されます．

また，上記で述べていないプログラムファイルの概要ですが，dbUpdater.pyはツイートから
抽出した単語と，その単語の出現頻度をデータベースへ保存します．
fetchStream.pyはTwitterのStreaming APIから日本語のツイートを取得するためのものです．
parse.pyは入力された文字列を形態素解析するためのプログラムで，
fileExtractor.pyは取得したツイートをparse.pyにより形態素解析し，抽出した単語を
dbUpdater.pyによりデータベースへ保存します．tsTfIdf.pyはこのプロダクトの要で，
データベースに保存された単語とその出現数からトレンドを計算します．
jsonCreator.pyは，計算結果を指定されたファイル名にjson形式で保存します．

最後にこのプロダクトの動作結果ですが，以下のURLにて公開しておりますので，
参考に見て頂ければと思います．
http://www.se.hiroshima-u.ac.jp/~shinjiro/TIATter/tiatter.htm

7. プロダクトをつくろうと思ったきっかけ
Twitterには日本だけでも，毎日１千万ほどのツイートが投稿されていると
言われています．これだけのツイート数があることから，Twitterは
自然に作成されるビッグデータと考えることができます．
私はこうした大量の文字列データを上手く利用すれば，表には決して
出てこない，隠された情報が見い出せるのではないかと思いました．
このような経緯からまずは，Twitter上で流行している単語を取得することで，
その時々に日本で起こっている出来事を手軽に把握できるようなプロダクトを
作ろう，と思うに至りました．

8. プロダクトの作成開始から完成までの期間
１ヶ月

9. プロダクトの作成人数
１人

10. プロダクトをつくる際に，技術的に工夫した点や苦労した点
工夫した点として，トレンドを計算する時間単位を任意に
設定できるよう作成した点があります．今回のプロダクトでは
１時間単位での計算となっていますが，パラメータを変えることで
数十分単位や１日単位などに設定可能です．これは，時間単位のスケールを
変えることで，トレンドから見えてくる情報の質も変化するため，
このように実装しました．また，トレンドの度合いを
数値として表現できるように制作したため，流行の規模が
どれだけかわかるようになっているのも，工夫した点です．

苦労した点には，データベースの管理があります．
取得するツイートは毎秒5,6ツイートになるため，
データベースへの書き込みはかなり頻繁に行われます．
そのため開発の初期ではSQLiteを利用していましたが，
処理が追いつかず正しく動作しませんでした．
そこで途中からPostgreSQLを使うように仕様を変更したことで，
動作を安定させることができました．




